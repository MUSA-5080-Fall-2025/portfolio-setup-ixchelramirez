---
title: "Lab4"
author: "Ixchel Ramirez"
date: "2025-11-17"
output: html_document
---

#Introduction
This lab looks into the correlation between 311 calls about street lights being out and burglaries. Lighting is often connected to people's perceptions on safety, people choose to walk a certain way at night because there are more street lights which enable them to see. I wanted to see how this perception of safety connects to burglary calls.  


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
install.packages("patchwork")


# Load required packages
library(tidyverse)      # Data manipulation
library(sf)             # Spatial operations
library(here)           # Relative file paths
library(viridis)        # Color scales
library(terra)          # Raster operations (replaces 'raster')
library(spdep)          # Spatial dependence
library(FNN)            # Fast nearest neighbors
library(MASS)           # Negative binomial regression
library(patchwork)      # Plot composition (replaces grid/gridExtra)
library(knitr)          # Tables
library(kableExtra)     # Table formatting
library(classInt)       # Classification intervals
library(here)
library(dplyr)
library(ggplot2)


# Spatstat split into sub-packages
library(spatstat.geom)    # Spatial geometries
library(spatstat.explore) # Spatial exploration/KDE

# Set options
options(scipen = 999)  # No scientific notation
set.seed(5080)         # Reproducibility

# Create consistent theme for visualizations
theme_crime <- function(base_size = 11) {
  theme_minimal(base_size = base_size) +
    theme(
      plot.title = element_text(face = "bold", size = base_size + 1),
      plot.subtitle = element_text(color = "gray30", size = base_size - 1),
      legend.position = "right",
      panel.grid.minor = element_blank(),
      axis.text = element_blank(),
      axis.title = element_blank()
    )
}

# Set as default
theme_set(theme_crime())

cat("✓ All packages loaded successfully!\n")
cat("✓ Working directory:", getwd(), "\n")

```

Above section loads in necessary packages to allow for functions to run, placing this at the beginning of the document helps it remain organized. 


#Chicago Spatial Data 
```{r cars}

# Load police districts (used for spatial cross-validation)
policeDistricts <- 
  st_read("https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(District = dist_num)

# Load police beats (smaller administrative units)
policeBeats <- 
  st_read("https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271') %>%
  dplyr::select(Beat = beat_num)

# Load Chicago boundary
chicagoBoundary <- 
  st_read("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson") %>%
  st_transform('ESRI:102271')

cat("✓ Loaded spatial boundaries\n")
cat("  - Police districts:", nrow(policeDistricts), "\n")
cat("  - Police beats:", nrow(policeBeats), "\n")


```

##Loaded in Chicago Spatial data 
The coordinate reference system is set to 'ESRI:102271' (Illinois State Plane East) because it minimizes distortion since all the data we are looking at is in Chicago. Additionally, since Chicago is in the US which feet as a system of measurement it removes the need to convert units and minimizes confusion and error in distance calculations.

#Burglary Data
```{r cars}

# Load from provided data file (downloaded from Chicago open data portal)

burglaries <- st_read(here("data", "burglaries.shp"))
burglaries <- st_transform(burglaries, crs = 'ESRI:102271')


# Check the data
cat("\n✓ Loaded burglary data\n")
cat("  - Number of burglaries:", nrow(burglaries), "\n")
cat("  - CRS:", st_crs(burglaries)$input, "\n")
cat("  - Date range:", min(burglaries$date, na.rm = TRUE), "to", 
    max(burglaries$date, na.rm = TRUE), "\n")


```
There are 7482 burglaries in the data set and the CRS is also set to Chicago which is useful for later calculations that check distance. If the datasets used different coordinate reference systems then problems would arise later when calculating distance. It is important to understand that while there are 7482 burglaries the spatial distribution of these is likely unequal and reflects where crime is surveilled rather than only where crime occurs. 

#Visualize point data

```{r cars}

# Simple point map
p1 <- ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
  geom_sf(data = burglaries, color = "#d62828", size = 0.1, alpha = 0.4) +
  labs(
    title = "Burglary Locations",
    subtitle = paste0("Chicago 2017, n = ", nrow(burglaries))
  )

# Density surface using modern syntax
p2 <- ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "gray95", color = "gray60") +
  geom_density_2d_filled(
    data = data.frame(st_coordinates(burglaries)),
    aes(X, Y),
    alpha = 0.7,
    bins = 8
  ) +
  scale_fill_viridis_d(
    option = "plasma",
    direction = -1,
    guide = "none"  # Modern ggplot2 syntax (not guide = FALSE)
  ) +
  labs(
    title = "Density Surface",
    subtitle = "Kernel density estimation"
  )

# Combine plots using patchwork (modern approach)
p1 + p2 + 
  plot_annotation(
    title = "Spatial Distribution of Burglaries in Chicago",
    tag_levels = 'A'
  )
```


Burglaries are not evenly distributed across Chicago, they are more frequent on the South Side of Chicago. There is also a high concentration on the Northeast side. The South Side of Chicago has a reputation for being dangerous which could result in an increased police presense as well as an increase in willingness to report the crimes here. 

#Creat the Fishnet
```{r create fishnet}

# Create 500m x 500m grid
fishnet <- st_make_grid(
  chicagoBoundary,
  cellsize = 500,  # 500 meters per cell
  square = TRUE
) %>%
  st_sf() %>%
  mutate(uniqueID = row_number())

# Keep only cells that intersect Chicago
fishnet <- fishnet[chicagoBoundary, ]

# View basic info
cat("✓ Created fishnet grid\n")
cat("  - Number of cells:", nrow(fishnet), "\n")
cat("  - Cell size:", 500, "x", 500, "meters\n")
cat("  - Cell area:", round(st_area(fishnet[1,])), "square meters\n")

```
The step above creates a fishnet grid which turns the point data into a grid of cells. Creating a grid provides a uniform unit of analysis so that one can aggregate counts, calculate spatial features and run regression models. Existing boundaries like neighborhoods and census tracts change which could result an added step when comparing years. Neighborhood boundaries are particularly harder to use because not everyone agrees on where a neighborhood begins and ends. While this approach helps with standardization it is harder to understand where burglaries occur (such as which neighborhood) because the grid does not delineate this. Thus, it requires a degree of familiarity with the area and where neighborhoods are to understand how social interactions influence the observations from the data. 

#Aggregate Burglaries to Grid
```{r aggregate-burglaries}
# Spatial join: which cell contains each burglary?
burglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID) %>%
  summarize(countBurglaries = n())

# Join back to fishnet (cells with 0 burglaries will be NA)
fishnet <- fishnet %>%
  left_join(burglaries_fishnet, by = "uniqueID") %>%
  mutate(countBurglaries = replace_na(countBurglaries, 0))

# Summary statistics
cat("\nBurglary count distribution:\n")
summary(fishnet$countBurglaries)
cat("\nCells with zero burglaries:", 
    sum(fishnet$countBurglaries == 0), 
    "/", nrow(fishnet),
    "(", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), "%)\n")

```


```{r visualize-fishnet}
#| fig-width: 8
#| fig-height: 6

# Visualize aggregated counts
ggplot() +
  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +
  geom_sf(data = chicagoBoundary, fill = NA, color = "white", linewidth = 1) +
  scale_fill_viridis_c(
    name = "Burglaries",
    option = "plasma",
    trans = "sqrt",  # Square root for better visualization of skewed data
    breaks = c(0, 1, 5, 10, 20, 40)
  ) +
  labs(
    title = "Burglary Counts by Grid Cell",
    subtitle = "500m x 500m cells, Chicago 2017"
  ) +
  theme_crime()


```

Burglaries are more dispersed in the South Side and in the core of the North. The largest cluster of cells with zero burglaries is also on the South Side. 


#Kernal Density Basemap
```{r kde-baseline}
#| message: false

# Convert burglaries to ppp (point pattern) format for spatstat
burglaries_ppp <- as.ppp(
  st_coordinates(burglaries),
  W = as.owin(st_bbox(chicagoBoundary))
)

# Calculate KDE with 1km bandwidth
kde_burglaries <- density.ppp(
  burglaries_ppp,
  sigma = 1000,  # 1km bandwidth
  edge = TRUE    # Edge correction
)

# Convert to terra raster (modern approach, not raster::raster)
kde_raster <- rast(kde_burglaries)

# Extract KDE values to fishnet cells
fishnet <- fishnet %>%
  mutate(
    kde_value = terra::extract(
      kde_raster,
      vect(fishnet),
      fun = mean,
      na.rm = TRUE
    )[, 2]  # Extract just the values column
  )

cat("✓ Calculated KDE baseline\n")

```


```{r visualize-kde}
#| fig-width: 8
#| fig-height: 6

ggplot() +
  geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +
  geom_sf(data = chicagoBoundary, fill = NA, color = "white", linewidth = 1) +
  scale_fill_viridis_c(
    name = "KDE Value",
    option = "plasma"
  ) +
  labs(
    title = "Kernel Density Estimation Baseline",
    subtitle = "Simple spatial smoothing of burglary locations"
  ) +
  theme_crime()

```


The above map looks very similar to the other patterns of crime in Chicago because a KDE baseline looks as what happens if an incident, in this case burglaries happens where they did before. This map counts the clusters of incidents well.

#Spatial predictor variables
```{r cars}

streetLights_allOut <- read_csv(here("data/311_Service_Requests_-_Street_Lights_-_All_Out_-_Historical_20251112.csv"))%>%
  filter(!is.na(Latitude), !is.na(Longitude)) %>%
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>%
  st_transform('ESRI:102271')

#cat("✓ Loaded street vehicle calls\n")
cat("  - Number of calls:", nrow(streetLights_allOut), "\n")

"data/311_Service_Requests_-_Street_Lights_-_All_Out_-_Historical_20251112.csv"

```


#Count of Street Lights all out per cell
```{r countstreetLights_allOut}
# Aggregate lights out to fishnet
lights_fishnet <- st_join(streetLights_allOut, fishnet, join = st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID) %>%
  summarize(streetLights_allOut = n())

# Join to fishnet
fishnet <- fishnet %>%
  left_join(lights_fishnet, by = "uniqueID") %>%
  mutate(streetLights_allOut = replace_na(streetLights_allOut, 0))

cat("All lights out distribution:\n")
summary(fishnet$streetLights_allOut)
```



```{r visualize-streetlights-allout}
#| fig-width: 10
#| fig-height: 4

p1 <- ggplot() +
  geom_sf(data = fishnet, aes(fill = streetLights_allOut), color = NA) +
  scale_fill_viridis_c(name = "Count", option = "magma") +
  labs(title = "All Lights Out 311 Calls") +
  theme_crime()

p2 <- ggplot() +
  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +
  scale_fill_viridis_c(name = "Count", option = "plasma") +
  labs(title = "Burglaries") +
  theme_crime()

p1 + p2 +
  plot_annotation(title = "Are street lights out and burglaries correlated?")

```


In this section I pulled data from Chicago's Open Data portal for 311 calls on street lights that are all out. Visually there are similarities between where burglairies occur and where street lights are all out specifically on the South Side there is more difference between these two categories in the North. This suggests that where street lights are out could help predict burglaries, but more likely just implies perceptions of safety.

#Nearest Neighbor 

Here we are calculating the mean distance to the 3 nearest blockw with all the lights out. 

```{r nn-feature}
#| message: false

# Calculate mean distance to 3 nearest lights out
# (Do this OUTSIDE of mutate to avoid sf conflicts)

# Get coordinates
fishnet_coords <- st_coordinates(st_centroid(fishnet))
lights_coords <- st_coordinates(streetLights_allOut)

# Calculate k nearest neighbors and distances
nn_result <- get.knnx(lights_coords, fishnet_coords, k = 3)

# Add to fishnet
fishnet <- fishnet %>%
  mutate(
    streetLights_allOut.nn = rowMeans(nn_result$nn.dist)
  )

cat("✓ Calculated nearest neighbor distances\n")
summary(fishnet$streetLights_allOut.nn)

```


A low value of streetLights_allOut.nn means means that the block is closer to other blocks with the lights out while a high value means that a cell is far from other cells with blocks that have the lights out. Blocks that have low value could indicate decreasing perceptions of safety. 


#Distance to Hot Spots
```{r}

#used this for local_moran becuase when it saves fishnet as fishnet it aborts 2. dplyr mutate + sf can still corrupt the geometry column

coords <- st_coordinates(st_centroid(fishnet))
neighbors <- knn2nb(knearneigh(coords, k = 5))
weights <- nb2listw(neighbors, style = "W", zero.policy = TRUE)

local_moran <- localmoran(fishnet[["streetLights_allOut"]], weights)
mean_val <- mean(fishnet[["streetLights_allOut"]], na.rm = TRUE)

fishnet$local_i <- local_moran[,1]
fishnet$p_value <- local_moran[,5]
fishnet$is_significant <- fishnet$p_value < 0.05

mean_val <- mean(fishnet$streetLights_allOut, na.rm = TRUE)

fishnet$moran_class <- dplyr::case_when(
  !fishnet$is_significant ~ "Not Significant",
  fishnet$local_i > 0 & fishnet$streetLights_allOut > mean_val ~ "High-High",
  fishnet$local_i > 0 & fishnet$streetLights_allOut <= mean_val ~ "Low-Low",
  fishnet$local_i < 0 & fishnet$streetLights_allOut > mean_val ~ "High-Low",
  fishnet$local_i < 0 & fishnet$streetLights_allOut <= mean_val ~ "Low-High"
)




```


```{r visualize-morans}
#| fig-width: 8
#| fig-height: 6

# Visualize hot spots
ggplot() +
  geom_sf(
    data = fishnet, 
    aes(fill = moran_class), 
    color = NA
  ) +
  scale_fill_manual(
    values = c(
      "High-High" = "#d7191c",
      "High-Low" = "#fdae61",
      "Low-High" = "#abd9e9",
      "Low-Low" = "#2c7bb6",
      "Not Significant" = "gray90"
    ),
    name = "Cluster Type"
  ) +
  labs(
    title = "Local Moran's I: Lights Out Clusters",
    subtitle = "High-High = Hot spots of disorder"
  ) +
  theme_crime()

#fill= moran_class is not running 

```

The distance to a cluster of lights that are out are helpful because it shows local spatial density while only looking at the distance to one specific point could be a random incident. From the distribution there are no areas with a high-low distribution and few areas with a low-high distribution. Low-low distributions, which are cold spots few lights are out and next to people without lights out, are clustered in the Southeast corner of Chicago, with patches around the boundary of the city. This means there are low values and its surrounded by other low values. High-high clusters are in the center of Chicago suggests that the observations are part of a cluster of high values and surrounded by high values i.e. street light blocks are out and they are next to other areas with street lights that are out. One thing to keep in mind is that the boundaries of Chicago have fewer neighbors thus this could bias the results and result with the spatial outliers such as high-low results. 

```{r distance-to-hotspots}
# Get centroids of "High-High" cells (hot spots)
hotspots <- fishnet %>%
  filter(moran_class == "High-High") %>%
  st_centroid()

# Calculate distance from each cell to nearest hot spot
if (nrow(hotspots) > 0) {
  fishnet <- fishnet %>%
    mutate(
      dist_to_hotspot = as.numeric(
        st_distance(st_centroid(fishnet), hotspots %>% st_union())
      )
    )
  
  cat("✓ Calculated distance to abandoned car hot spots\n")
  cat("  - Number of hot spot cells:", nrow(hotspots), "\n")
} else {
  fishnet <- fishnet %>%
    mutate(dist_to_hotspot = 0)
  cat("⚠ No significant hot spots found\n")
}

```
There are 297 hot spots.


#Cross Validation 
```{r join-districts}
# Join district information to fishnet
fishnet <- st_join(
  fishnet,
  policeDistricts,
  join = st_within,
  left = TRUE
) %>%
  filter(!is.na(District))  # Remove cells outside districts

cat("✓ Joined police districts\n")
cat("  - Districts:", length(unique(fishnet$District)), "\n")
cat("  - Cells:", nrow(fishnet), "\n")

```
Police districts are used for the spatial cross-validation because we are using crime data.


#Poisson Regression
```{r prepare-data}
# Create clean modeling dataset
fishnet_model <- fishnet %>%
  st_drop_geometry() %>%
  dplyr::select(
    uniqueID,
    District,
    countBurglaries,
    streetLights_allOut,
    streetLights_allOut.nn,
    dist_to_hotspot
  ) %>%
  na.omit()  # Remove any remaining NAs

cat("✓ Prepared modeling data\n")
cat("  - Observations:", nrow(fishnet_model), "\n")
cat("  - Variables:", ncol(fishnet_model), "\n")

```
There are 1708 observations and 6 variables. All of the values are positive because we are counting and cannot have a negative number.


```{r}
fishnet_safe <- data.frame(
  countBurglaries      = as.numeric(fishnet_model$countBurglaries),
  streetLights_allOut  = as.numeric(fishnet_model$streetLights_allOut),
  streetLights_allOut.nn = as.numeric(fishnet_model$streetLights_allOut.nn),
  dist_to_hotspot      = as.numeric(fishnet_model$dist_to_hotspot)
)

# Remove row.names just in case
rownames(fishnet_safe) <- NULL

# Confirm attributes might not need attributes through glm just need to write.csv so could delete
attributes(fishnet_safe)

glm(countBurglaries ~ streetLights_allOut, data = fishnet_safe, family = poisson())
glm(countBurglaries ~ streetLights_allOut.nn, data = fishnet_safe, family = poisson())
glm(countBurglaries ~ dist_to_hotspot, data = fishnet_safe, family = poisson())
glm(countBurglaries ~ streetLights_allOut + streetLights_allOut.nn + dist_to_hotspot,
    data = fishnet_safe, family = poisson())

write.csv(fishnet_safe, "fishnet_safe.csv", row.names = FALSE)
fishnet_reload <- read.csv("fishnet_safe.csv")

glm(countBurglaries ~ streetLights_allOut + streetLights_allOut.nn + dist_to_hotspot,
    data = fishnet_reload, family = poisson())


library(speedglm)


model_poisson <- speedglm(
  countBurglaries ~ streetLights_allOut + streetLights_allOut.nn + dist_to_hotspot,
  data = fishnet_reload,
  family = poisson()
)

summary(model_poisson)

```

The Poisson regression results indicate that burglary counts are significantly associated with street lighting conditions and proximity to known hotspots. Blocks with more streetlights out tend to experience slightly higher numbers of burglaries, while blocks that are farther from other lights-out blocks have lower expected burglary counts, suggesting that clusters of poorly lit areas are more vulnerable. Additionally, blocks located closer to established burglary hotspots are at greater risk. All three predictors—total street lights out (12.91), mean distance to other lights-out blocks (-19.1), and distance to hotspots (-10.72) are highly significant based on their values. The model shows that areas with less lighting are more likely to be near areas where more burglary is reported.

```{r check-overdispersion}
# Calculate dispersion parameter
df_resid <- nrow(fishnet_reload) - length(model_poisson$coefficients)

dispersion <- model_poisson$deviance / df_resid
dispersion

if (dispersion > 1.5) {
  cat("⚠ Overdispersion detected! Consider Negative Binomial model.\n")
} else {
  cat("✓ Dispersion looks okay for Poisson model.\n")
}
```
Overdispersion is detected which means the variance of the response variable exceeds it's mean, which is an assumption in the Poisson distribution. 

#Negative Binomial Regression 
```{r fit-negbin}

##ALternative way to get negative binomial regression

# Fit NB using Poisson coefficients as starting values
poisson_coefs <- coef(glm(
  countBurglaries ~ streetLights_allOut + streetLights_allOut.nn + dist_to_hotspot,
  data = fishnet_reload,
  family = poisson()
))

model_nb <- glm.nb(
  countBurglaries ~ streetLights_allOut + streetLights_allOut.nn + dist_to_hotspot,
  data = fishnet_reload,
  init.theta = 1,               # initial theta
  control = glm.control(maxit = 100, epsilon = 1e-8),
  start = poisson_coefs         # start from Poisson estimates
)
summary(model_nb)

cat("\nModel Comparison:\n")
cat("Poisson AIC:", round(AIC(model_poisson), 1), "\n")
cat("Negative Binomial AIC:", round(AIC(model_nb), 1), "\n")

```

The negative binomial regression results show that all three predictors are highly significant, which is consistent with the Poisson model. More streetlights out is associated with higher burglary counts, greater distance to other lights-out blocks is associated with fewer burglaries, and closer proximity to a hotspot increases burglary risk. The negative binomial model accounts for overdispersion in the data, which we saw above. 

Looking at the AIC, the Negative Binomial Model has a lower AIC, 7464.1, than the Poisson model, 8852.5, indicating that it provides a better fit for the data. The Negative Binomial Model having a better fit makes sense given that the assumption of equal mean and variance is violated for the Poisson model. This means the Negative Binomial Model is better at capturing burglary reports in Chicago.


Part 5 and 6 could not be completed as I continued to run into an error in step 5. 
